{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c919045-d53c-4290-a65f-140ae526e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1cd1975-80b4-4363-a616-fb95d91255b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPG</th>\n",
       "      <th>HOMA_IR</th>\n",
       "      <th>Total_TAG</th>\n",
       "      <th>2hr_OGTT</th>\n",
       "      <th>T_CE</th>\n",
       "      <th>T_TAG</th>\n",
       "      <th>T_DAG</th>\n",
       "      <th>T_FFA</th>\n",
       "      <th>T_PC</th>\n",
       "      <th>T_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>total DMA</th>\n",
       "      <th>alpha-AAA</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Kynurenine</th>\n",
       "      <th>Met-SO</th>\n",
       "      <th>t4-OH-Pro</th>\n",
       "      <th>Putrescine</th>\n",
       "      <th>Serotonin</th>\n",
       "      <th>Spermidine</th>\n",
       "      <th>Taurine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.426266</td>\n",
       "      <td>2.336573</td>\n",
       "      <td>5.781363</td>\n",
       "      <td>6.491854</td>\n",
       "      <td>12.09865</td>\n",
       "      <td>10.273816</td>\n",
       "      <td>4.086167</td>\n",
       "      <td>9.443437</td>\n",
       "      <td>10.80714</td>\n",
       "      <td>7.199930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>1.874979</td>\n",
       "      <td>6.710942</td>\n",
       "      <td>2.394366</td>\n",
       "      <td>-5.852678</td>\n",
       "      <td>4.214117</td>\n",
       "      <td>-3.462398</td>\n",
       "      <td>-1.018531</td>\n",
       "      <td>-1.642998</td>\n",
       "      <td>6.532927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.741468</td>\n",
       "      <td>3.109857</td>\n",
       "      <td>7.906891</td>\n",
       "      <td>7.451211</td>\n",
       "      <td>12.09865</td>\n",
       "      <td>10.807138</td>\n",
       "      <td>4.907486</td>\n",
       "      <td>8.901539</td>\n",
       "      <td>10.27382</td>\n",
       "      <td>7.402848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692381</td>\n",
       "      <td>-0.488355</td>\n",
       "      <td>6.008138</td>\n",
       "      <td>0.756260</td>\n",
       "      <td>-3.400239</td>\n",
       "      <td>2.677591</td>\n",
       "      <td>-3.313604</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>-2.012510</td>\n",
       "      <td>7.612722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.672426</td>\n",
       "      <td>3.621295</td>\n",
       "      <td>7.000001</td>\n",
       "      <td>6.942515</td>\n",
       "      <td>12.09865</td>\n",
       "      <td>10.273816</td>\n",
       "      <td>4.379796</td>\n",
       "      <td>8.802699</td>\n",
       "      <td>10.80714</td>\n",
       "      <td>6.759415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032965</td>\n",
       "      <td>0.487615</td>\n",
       "      <td>6.008138</td>\n",
       "      <td>1.285267</td>\n",
       "      <td>-4.594876</td>\n",
       "      <td>3.496043</td>\n",
       "      <td>-7.375598</td>\n",
       "      <td>-1.504665</td>\n",
       "      <td>-2.644530</td>\n",
       "      <td>6.185453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.491854</td>\n",
       "      <td>1.563326</td>\n",
       "      <td>7.011228</td>\n",
       "      <td>6.629358</td>\n",
       "      <td>12.09865</td>\n",
       "      <td>10.273816</td>\n",
       "      <td>4.281923</td>\n",
       "      <td>8.522484</td>\n",
       "      <td>10.80714</td>\n",
       "      <td>6.948541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226960</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>6.440727</td>\n",
       "      <td>2.198089</td>\n",
       "      <td>-2.392424</td>\n",
       "      <td>4.504812</td>\n",
       "      <td>-3.638916</td>\n",
       "      <td>-2.520678</td>\n",
       "      <td>-2.473015</td>\n",
       "      <td>5.894638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.539160</td>\n",
       "      <td>1.997820</td>\n",
       "      <td>6.285404</td>\n",
       "      <td>6.954197</td>\n",
       "      <td>12.09865</td>\n",
       "      <td>9.228706</td>\n",
       "      <td>3.965879</td>\n",
       "      <td>8.901539</td>\n",
       "      <td>10.80714</td>\n",
       "      <td>7.082903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018463</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>6.532927</td>\n",
       "      <td>2.766317</td>\n",
       "      <td>-8.606643</td>\n",
       "      <td>3.550989</td>\n",
       "      <td>-2.483951</td>\n",
       "      <td>-1.491908</td>\n",
       "      <td>-1.194648</td>\n",
       "      <td>6.267509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FPG   HOMA_IR  Total_TAG  2hr_OGTT      T_CE      T_TAG     T_DAG  \\\n",
       "0  6.426266  2.336573   5.781363  6.491854  12.09865  10.273816  4.086167   \n",
       "1  6.741468  3.109857   7.906891  7.451211  12.09865  10.807138  4.907486   \n",
       "2  6.672426  3.621295   7.000001  6.942515  12.09865  10.273816  4.379796   \n",
       "3  6.491854  1.563326   7.011228  6.629358  12.09865  10.273816  4.281923   \n",
       "4  6.539160  1.997820   6.285404  6.954197  12.09865   9.228706  3.965879   \n",
       "\n",
       "      T_FFA      T_PC      T_PE  ...  total DMA  alpha-AAA  Creatinine  \\\n",
       "0  9.443437  10.80714  7.199930  ...   0.111588   1.874979    6.710942   \n",
       "1  8.901539  10.27382  7.402848  ...  -0.692381  -0.488355    6.008138   \n",
       "2  8.802699  10.80714  6.759415  ...  -0.032965   0.487615    6.008138   \n",
       "3  8.522484  10.80714  6.948541  ...   0.226960   0.382100    6.440727   \n",
       "4  8.901539  10.80714  7.082903  ...   1.018463   0.024295    6.532927   \n",
       "\n",
       "   Kynurenine    Met-SO  t4-OH-Pro  Putrescine  Serotonin  Spermidine  \\\n",
       "0    2.394366 -5.852678   4.214117   -3.462398  -1.018531   -1.642998   \n",
       "1    0.756260 -3.400239   2.677591   -3.313604   0.813043   -2.012510   \n",
       "2    1.285267 -4.594876   3.496043   -7.375598  -1.504665   -2.644530   \n",
       "3    2.198089 -2.392424   4.504812   -3.638916  -2.520678   -2.473015   \n",
       "4    2.766317 -8.606643   3.550989   -2.483951  -1.491908   -1.194648   \n",
       "\n",
       "    Taurine  \n",
       "0  6.532927  \n",
       "1  7.612722  \n",
       "2  6.185453  \n",
       "3  5.894638  \n",
       "4  6.267509  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('Diabetes dataset_Group12.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(columns = \"ID\")\n",
    "new_df = df.drop(columns = \"Label\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce126972-2a8e-4e27-a444-a01e888a33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['Label'] = df['Label'].astype(str)\n",
    "df['Label'] = encoder.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0005cfc6-7861-4dfe-82ae-36297910722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = new_df\n",
    "\n",
    "# Create our target\n",
    "y = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ff13a1-9df5-4427-9c73-78a5d38246cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPG</th>\n",
       "      <th>HOMA_IR</th>\n",
       "      <th>Total_TAG</th>\n",
       "      <th>2hr_OGTT</th>\n",
       "      <th>T_CE</th>\n",
       "      <th>T_TAG</th>\n",
       "      <th>T_DAG</th>\n",
       "      <th>T_FFA</th>\n",
       "      <th>T_PC</th>\n",
       "      <th>T_PE</th>\n",
       "      <th>...</th>\n",
       "      <th>total DMA</th>\n",
       "      <th>alpha-AAA</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Kynurenine</th>\n",
       "      <th>Met-SO</th>\n",
       "      <th>t4-OH-Pro</th>\n",
       "      <th>Putrescine</th>\n",
       "      <th>Serotonin</th>\n",
       "      <th>Spermidine</th>\n",
       "      <th>Taurine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.614549</td>\n",
       "      <td>2.701736</td>\n",
       "      <td>6.844076</td>\n",
       "      <td>6.926155</td>\n",
       "      <td>12.133278</td>\n",
       "      <td>10.319602</td>\n",
       "      <td>4.323889</td>\n",
       "      <td>8.893333</td>\n",
       "      <td>10.669212</td>\n",
       "      <td>7.054732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254614</td>\n",
       "      <td>0.079763</td>\n",
       "      <td>6.135712</td>\n",
       "      <td>1.663323</td>\n",
       "      <td>-3.658187</td>\n",
       "      <td>3.805103</td>\n",
       "      <td>-3.972084</td>\n",
       "      <td>-2.809970</td>\n",
       "      <td>-2.167594</td>\n",
       "      <td>5.531168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.139946</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>0.822207</td>\n",
       "      <td>0.336438</td>\n",
       "      <td>0.128341</td>\n",
       "      <td>0.613956</td>\n",
       "      <td>0.329148</td>\n",
       "      <td>0.324070</td>\n",
       "      <td>0.235568</td>\n",
       "      <td>0.295159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840540</td>\n",
       "      <td>0.865511</td>\n",
       "      <td>0.491906</td>\n",
       "      <td>0.682331</td>\n",
       "      <td>2.969190</td>\n",
       "      <td>0.772432</td>\n",
       "      <td>1.907039</td>\n",
       "      <td>2.188667</td>\n",
       "      <td>0.738385</td>\n",
       "      <td>0.906282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.339851</td>\n",
       "      <td>0.706960</td>\n",
       "      <td>5.584967</td>\n",
       "      <td>5.882646</td>\n",
       "      <td>12.098650</td>\n",
       "      <td>9.004653</td>\n",
       "      <td>3.531287</td>\n",
       "      <td>8.110500</td>\n",
       "      <td>10.273820</td>\n",
       "      <td>6.440727</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.520678</td>\n",
       "      <td>-2.973741</td>\n",
       "      <td>4.784064</td>\n",
       "      <td>-0.014012</td>\n",
       "      <td>-10.044284</td>\n",
       "      <td>1.285267</td>\n",
       "      <td>-10.044283</td>\n",
       "      <td>-10.044283</td>\n",
       "      <td>-4.181955</td>\n",
       "      <td>3.590169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.515637</td>\n",
       "      <td>2.153218</td>\n",
       "      <td>6.228442</td>\n",
       "      <td>6.703892</td>\n",
       "      <td>12.098650</td>\n",
       "      <td>10.273816</td>\n",
       "      <td>4.090292</td>\n",
       "      <td>8.710862</td>\n",
       "      <td>10.407150</td>\n",
       "      <td>6.849232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779078</td>\n",
       "      <td>-0.344862</td>\n",
       "      <td>5.824147</td>\n",
       "      <td>1.085826</td>\n",
       "      <td>-5.841102</td>\n",
       "      <td>3.483871</td>\n",
       "      <td>-4.613421</td>\n",
       "      <td>-3.881660</td>\n",
       "      <td>-2.587629</td>\n",
       "      <td>4.789947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.607312</td>\n",
       "      <td>2.538648</td>\n",
       "      <td>6.761414</td>\n",
       "      <td>6.906891</td>\n",
       "      <td>12.098650</td>\n",
       "      <td>10.273816</td>\n",
       "      <td>4.331543</td>\n",
       "      <td>8.901539</td>\n",
       "      <td>10.807140</td>\n",
       "      <td>7.043002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145946</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>6.244521</td>\n",
       "      <td>1.781592</td>\n",
       "      <td>-2.782335</td>\n",
       "      <td>3.868034</td>\n",
       "      <td>-3.405381</td>\n",
       "      <td>-2.407604</td>\n",
       "      <td>-2.127347</td>\n",
       "      <td>5.723925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.700441</td>\n",
       "      <td>3.319494</td>\n",
       "      <td>7.266787</td>\n",
       "      <td>7.199572</td>\n",
       "      <td>12.098650</td>\n",
       "      <td>10.673808</td>\n",
       "      <td>4.568362</td>\n",
       "      <td>9.111264</td>\n",
       "      <td>10.807140</td>\n",
       "      <td>7.243204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328442</td>\n",
       "      <td>0.473564</td>\n",
       "      <td>6.532927</td>\n",
       "      <td>2.162975</td>\n",
       "      <td>-1.191318</td>\n",
       "      <td>4.229380</td>\n",
       "      <td>-2.652177</td>\n",
       "      <td>-1.466755</td>\n",
       "      <td>-1.567777</td>\n",
       "      <td>6.185453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.965785</td>\n",
       "      <td>5.093344</td>\n",
       "      <td>8.774787</td>\n",
       "      <td>7.507795</td>\n",
       "      <td>12.600750</td>\n",
       "      <td>11.408379</td>\n",
       "      <td>4.907486</td>\n",
       "      <td>9.443437</td>\n",
       "      <td>10.807140</td>\n",
       "      <td>7.769827</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193675</td>\n",
       "      <td>2.141128</td>\n",
       "      <td>6.798392</td>\n",
       "      <td>3.029029</td>\n",
       "      <td>1.045463</td>\n",
       "      <td>5.202502</td>\n",
       "      <td>-1.147408</td>\n",
       "      <td>0.972990</td>\n",
       "      <td>-0.933018</td>\n",
       "      <td>7.612722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FPG    HOMA_IR  Total_TAG   2hr_OGTT       T_CE      T_TAG  \\\n",
       "count  58.000000  58.000000  58.000000  58.000000  58.000000  58.000000   \n",
       "mean    6.614549   2.701736   6.844076   6.926155  12.133278  10.319602   \n",
       "std     0.139946   0.923355   0.822207   0.336438   0.128341   0.613956   \n",
       "min     6.339851   0.706960   5.584967   5.882646  12.098650   9.004653   \n",
       "25%     6.515637   2.153218   6.228442   6.703892  12.098650  10.273816   \n",
       "50%     6.607312   2.538648   6.761414   6.906891  12.098650  10.273816   \n",
       "75%     6.700441   3.319494   7.266787   7.199572  12.098650  10.673808   \n",
       "max     6.965785   5.093344   8.774787   7.507795  12.600750  11.408379   \n",
       "\n",
       "           T_DAG      T_FFA       T_PC       T_PE  ...  total DMA  alpha-AAA  \\\n",
       "count  58.000000  58.000000  58.000000  58.000000  ...  58.000000  58.000000   \n",
       "mean    4.323889   8.893333  10.669212   7.054732  ...  -0.254614   0.079763   \n",
       "std     0.329148   0.324070   0.235568   0.295159  ...   0.840540   0.865511   \n",
       "min     3.531287   8.110500  10.273820   6.440727  ...  -2.520678  -2.973741   \n",
       "25%     4.090292   8.710862  10.407150   6.849232  ...  -0.779078  -0.344862   \n",
       "50%     4.331543   8.901539  10.807140   7.043002  ...  -0.145946   0.150635   \n",
       "75%     4.568362   9.111264  10.807140   7.243204  ...   0.328442   0.473564   \n",
       "max     4.907486   9.443437  10.807140   7.769827  ...   1.193675   2.141128   \n",
       "\n",
       "       Creatinine  Kynurenine     Met-SO  t4-OH-Pro  Putrescine  Serotonin  \\\n",
       "count   58.000000   58.000000  58.000000  58.000000   58.000000  58.000000   \n",
       "mean     6.135712    1.663323  -3.658187   3.805103   -3.972084  -2.809970   \n",
       "std      0.491906    0.682331   2.969190   0.772432    1.907039   2.188667   \n",
       "min      4.784064   -0.014012 -10.044284   1.285267  -10.044283 -10.044283   \n",
       "25%      5.824147    1.085826  -5.841102   3.483871   -4.613421  -3.881660   \n",
       "50%      6.244521    1.781592  -2.782335   3.868034   -3.405381  -2.407604   \n",
       "75%      6.532927    2.162975  -1.191318   4.229380   -2.652177  -1.466755   \n",
       "max      6.798392    3.029029   1.045463   5.202502   -1.147408   0.972990   \n",
       "\n",
       "       Spermidine    Taurine  \n",
       "count   58.000000  58.000000  \n",
       "mean    -2.167594   5.531168  \n",
       "std      0.738385   0.906282  \n",
       "min     -4.181955   3.590169  \n",
       "25%     -2.587629   4.789947  \n",
       "50%     -2.127347   5.723925  \n",
       "75%     -1.567777   6.185453  \n",
       "max     -0.933018   7.612722  \n",
       "\n",
       "[8 rows x 105 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6392a8d9-c4d5-44eb-95ea-67129680127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30\n",
       "0    28\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473c2372-bbca-4c5e-83b3-06ba64fa6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668db5ed-21c6-4b92-8c57-8e1df449e4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the multiple linear regression model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d2ac9d-7a21-44b1-b0ec-2e9c5d295527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           0       0\n",
       "1           0       1\n",
       "2           1       1\n",
       "3           0       1\n",
       "4           0       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "results = pd.DataFrame({\n",
    "   \"Prediction\": y_pred,\n",
    "   \"Actual\": y_test\n",
    "}).reset_index(drop=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "538526ae-224b-416c-8feb-699cbef13787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9003bcdf-98c7-4800-a60b-a0873f530c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63         7\n",
      "           1       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.61      0.61      0.60        15\n",
      "weighted avg       0.61      0.60      0.60        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf2cb47-8454-4df7-8977-7f5770d724f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Easy Ensemble AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6640ab92-836d-4cac-807c-21cc4c588095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "easyensemb = EasyEnsembleClassifier(n_estimators = 100, random_state=1)\n",
    "easyensemb = easyensemb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94870f84-6f94-4768-83ce-771f8ba692ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5982142857142857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "yprediction = easyensemb.predict(X_test)\n",
    "balanced_accuracy_score(y_test, yprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f2b1dd4-8b93-4f30-95e4-46c2684b099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, yprediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be97010f-ff0a-4591-8d4f-2908850a8389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.57      0.57      0.62      0.57      0.60      0.36         7\n",
      "          1       0.62      0.62      0.57      0.62      0.60      0.36         8\n",
      "\n",
      "avg / total       0.60      0.60      0.60      0.60      0.60      0.36        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "\n",
    "report = classification_report_imbalanced(y_test, yprediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adbf8a0b-ce88-418f-8571-3fceefa76ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca0d451-83dd-49d6-ad11-59ca0a859679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 22, 1: 22})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ac8571-cc15-4053-a409-639537639c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "naive = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "naive.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d4d8205-2a14-4540-a04d-297ffa1db3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "yprediction = naive.predict(X_test)\n",
    "balanced_accuracy_score(y_test, yprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f79e96a-d883-4ee2-8e67-6d5ec4d1d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, yprediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a1c38e6-c072-40b8-b918-949b5a4952e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.60      0.86      0.50      0.71      0.65      0.44         7\n",
      "          1       0.80      0.50      0.86      0.62      0.65      0.41         8\n",
      "\n",
      "avg / total       0.71      0.67      0.69      0.66      0.65      0.43        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "report = classification_report_imbalanced(y_test, yprediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b835fd5-ed61-441a-bf9e-f23fca76aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9f34d41-7679-4efe-8c5e-45c56039095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 21, 1: 21})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e87ecc8-45e2-4e66-bd8f-34cbe1681444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "under = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "under.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b8ad9a3-e69a-4cb3-9563-3ea8dcb88e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6160714285714286"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "yprediction = under.predict(X_test)\n",
    "balanced_accuracy_score(y_test, yprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35eafdb1-d43d-422c-a79b-8039bfc93cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1]\n",
      " [5 3]]\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, yprediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdf72bbf-10b8-4ff9-880c-ee6ae224f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.55      0.86      0.38      0.67      0.57      0.34         7\n",
      "          1       0.75      0.38      0.86      0.50      0.57      0.31         8\n",
      "\n",
      "avg / total       0.65      0.60      0.63      0.58      0.57      0.32        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "report = classification_report_imbalanced(y_test, yprediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23d2b372-7670-4d7b-b9ba-c9e93d579163",
   "metadata": {},
   "outputs": [],
   "source": [
    "##combination Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2eda3018-9083-402a-99c4-0ae281837372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10, 1: 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "smoteenn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc7440c9-6f39-45fe-8eee-8bdd481c5512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "comb = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "comb.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b20a17-d088-42ca-bbb9-fd69dfdd8604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "yprediction = comb.predict(X_test)\n",
    "balanced_accuracy_score(y_test, yprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5eace580-d349-4f71-930c-1bff7aa0716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "matrix = confusion_matrix(y_test, yprediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c34c568-337e-4dc1-a9dc-4daeddb134db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.60      0.86      0.50      0.71      0.65      0.44         7\n",
      "          1       0.80      0.50      0.86      0.62      0.65      0.41         8\n",
      "\n",
      "avg / total       0.71      0.67      0.69      0.66      0.65      0.43        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "report = classification_report_imbalanced(y_test, yprediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b70dc9-fc46-41d8-aad7-669b91f55152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
